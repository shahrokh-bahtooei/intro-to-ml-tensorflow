{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "k7sePAkWpLJV",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Saving and Loading Models\n",
    "\n",
    "In this notebook, we'll see how to save and load models with TensorFlow. This is important because you'll often want to load previously trained models to use in making predictions or to continue training on new data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tD856SqhH4JK",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Import Resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Hsu5egUUqPg9",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "tfds.disable_progress_bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "logger = tf.get_logger()\n",
    "logger.setLevel(logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "BqsrWYDKp4Fd",
    "outputId": "5fe90392-c56f-423f-bc89-b9fc985feecf",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using:\n",
      "\t• TensorFlow version: 2.9.1\n",
      "\t• tf.keras version: 2.9.0\n",
      "\t• GPU device not found. Running on CPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-18 12:08:47.803824: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "print('Using:')\n",
    "print('\\t\\u2022 TensorFlow version:', tf.__version__)\n",
    "print('\\t\\u2022 tf.keras version:', tf.keras.__version__)\n",
    "print('\\t\\u2022 Running on GPU' if tf.test.is_gpu_available() else '\\t\\u2022 GPU device not found. Running on CPU')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dAe81nXoICzC",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Load the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 207
    },
    "colab_type": "code",
    "id": "bxcg_ZbuLnM3",
    "outputId": "33841a52-53e6-4e8a-ecbd-b448bf3c46f5",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "splits = ['train[:80%]', 'train[80%:]', 'test']\n",
    "\n",
    "dataset, dataset_info = tfds.load('fashion_mnist', split=splits, as_supervised=True, with_info=True)\n",
    "\n",
    "training_set, validation_set, test_set = dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "z1WhOLC7Ii3D",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Explore the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "9i2586KjI4QM",
    "outputId": "24ccc17a-c3f6-44ba-edc3-ae267e628fc2",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 48,000 images in the training set\n",
      "There are 12,000 images in the validation set\n",
      "There are 10,000 images in the test set\n"
     ]
    }
   ],
   "source": [
    "num_training_examples = len(training_set)\n",
    "num_validation_examples = len(validation_set)\n",
    "num_test_examples = len(test_set)\n",
    "\n",
    "print(f'There are {num_training_examples:,} images in the training set')\n",
    "print(f'There are {num_validation_examples:,} images in the validation set')\n",
    "print(f'There are {num_test_examples:,} images in the test set')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RLMJCpppq43U",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 280
    },
    "colab_type": "code",
    "id": "PeU9nb_xqW98",
    "outputId": "7e35ce36-2589-4b3e-b2bf-313eaa2414f0",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-18 12:08:48.012897: W tensorflow/core/kernels/data/cache_dataset_ops.cc:856] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 2 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "image/png": {
       "width": 305,
       "height": 263
      },
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for image, label in training_set.take(1):\n",
    "    image = image.numpy().squeeze()\n",
    "    label = label.numpy()\n",
    "\n",
    "plt.imshow(image, cmap=plt.cm.binary)\n",
    "plt.title(class_names[label])\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "k5rUDqxBIt5N",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Create Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ec3uphcyci3c",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def normalize(image, label):\n",
    "    image = tf.cast(image, tf.float32)\n",
    "    image /= 255\n",
    "    return image, label\n",
    "\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "training_batches = training_set.cache().shuffle(num_training_examples // 4).batch(batch_size).map(normalize).prefetch(1)\n",
    "validation_batches = validation_set.cache().batch(batch_size).map(normalize).prefetch(1)\n",
    "testing_batches = test_set.cache().batch(batch_size).map(normalize).prefetch(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ySQuJ-iPqNoR",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Build and Train the Model\n",
    "\n",
    "Here we'll build and compile our model as usual."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 425
    },
    "colab_type": "code",
    "id": "47Vnu0KJMqwc",
    "outputId": "f1abd9d1-db9e-4bfd-99c7-d4376adb8745",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten (Flatten)           (None, 784)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               401920    \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 512)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 256)               131328    \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 128)               32896     \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 567,434\n",
      "Trainable params: 567,434\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "layer_neurons = [512, 256, 128]\n",
    "\n",
    "dropout_rate = 0.5\n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "\n",
    "model.add(tf.keras.layers.Flatten(input_shape=(28, 28, 1)))\n",
    "\n",
    "for neurons in layer_neurons:\n",
    "    model.add(tf.keras.layers.Dense(neurons, activation='relu'))\n",
    "    model.add(tf.keras.layers.Dropout(dropout_rate))\n",
    "\n",
    "model.add(tf.keras.layers.Dense(10, activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 153
    },
    "colab_type": "code",
    "id": "1qLJ-cAwnmFD",
    "outputId": "32be0a8a-5cfb-473f-872c-e09da279eae5",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "750/750 [==============================] - 6s 7ms/step - loss: 0.8081 - accuracy: 0.7032 - val_loss: 0.4774 - val_accuracy: 0.8282\n",
      "Epoch 2/4\n",
      "750/750 [==============================] - 3s 4ms/step - loss: 0.5573 - accuracy: 0.8037 - val_loss: 0.4129 - val_accuracy: 0.8446\n",
      "Epoch 3/4\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.5122 - accuracy: 0.8212 - val_loss: 0.3895 - val_accuracy: 0.8540\n",
      "Epoch 4/4\n",
      "750/750 [==============================] - 3s 5ms/step - loss: 0.4843 - accuracy: 0.8314 - val_loss: 0.3779 - val_accuracy: 0.8612\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "EPOCHS = 4\n",
    "\n",
    "history = model.fit(training_batches,\n",
    "                    epochs=EPOCHS,\n",
    "                    validation_data=validation_batches)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jseIvfe2xb56",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Saving and Loading Models\n",
    "\n",
    "In TensorFlow we can save our trained models in different formats. Here we will see how to save our models in TensorFlow's SavedModel format and as HDF5 files, which is the format used by Keras models.\n",
    "\n",
    "### Saving and Loading Models in HDF5 Format\n",
    "\n",
    "To save our models in the format used by Keras models we use the `.save(filepath)` method. For example, to save a model called `my_model` in the current working directory with the name `test_model` we use:\n",
    "\n",
    "```python\n",
    "my_model.save('./test_model.h5')\n",
    "```\n",
    "\n",
    "It's important to note that we have to provide the `.h5` extension to the `filepath` in order the tell `tf.keras` to save our model as an HDF5 file. \n",
    "\n",
    "The above command saves our model into a single HDF5 file that will contain:\n",
    "\n",
    "* The model's architecture.\n",
    "* The model's weight values which were learned during training.\n",
    "* The model's training configuration, which corresponds to the parameters you passed to the `compile` method.\n",
    "* The optimizer and its state. This allows you to resume training exactly where you left off.\n",
    "\n",
    "\n",
    "In the cell below we save our trained `model` as an HDF5 file. The name of our HDF5 will correspond to the current time stamp. This is useful if you are saving many models and want each of them to have a unique name. By default the `.save()` method will **silently** overwrite any existing file at the target location with the same name. If we want `tf.keras` to provide us with a manual prompt to whether overwrite files with the same name, you can set the argument `overwrite=False` in the `.save()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "G1dOvNRvrhNa",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "t = time.time()\n",
    "\n",
    "saved_keras_model_filepath = f'./Part_6/hdf5/{int(t)}.h5'\n",
    "\n",
    "model.save(saved_keras_model_filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lGNRBb1puSRg",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Once a model has been saved, we can use `tf.keras.models.load_model(filepath)` to re-load our model. This command will also compile our model automatically using the saved training configuration, unless the model was never compiled in the first place."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 547
    },
    "colab_type": "code",
    "id": "akaAVE2js5d0",
    "outputId": "84301998-a6c3-4a55-c5f1-f76d086290bf",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten (Flatten)           (None, 784)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               401920    \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 512)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 256)               131328    \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 128)               32896     \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 567,434\n",
      "Trainable params: 567,434\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "reloaded_keras_model = tf.keras.models.load_model(saved_keras_model_filepath)\n",
    "\n",
    "reloaded_keras_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xWihP1oMjNeF",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "As we can see the re-loaded model has the same architecture as our original model, as it should be. At this point, since we haven't done anything new to the re-loaded model, then both the `reloaded_keras_model` and our original `model` should be identical copies. Therefore, they should make the same predictions on the same images. Let's check that this is true:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "gLQsw7QVkElc",
    "outputId": "0d00e16b-9fdd-4d34-b9ab-96956ddbf5a5",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-18 12:19:05.015559: W tensorflow/core/kernels/data/cache_dataset_ops.cc:856] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2022-08-18 12:19:05.015876: W tensorflow/core/kernels/data/cache_dataset_ops.cc:856] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    }
   ],
   "source": [
    "for image_batch, label_batch in testing_batches.take(1):\n",
    "    prediction_1 = model.predict(image_batch)\n",
    "    prediction_2 = reloaded_keras_model.predict(image_batch)\n",
    "    difference = np.abs(prediction_1 - prediction_2)\n",
    "    print(difference.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "K-dDOY0BmYhs",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "As we can see, the result is 0.0, which indicates that both models made the same predictions on the same images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lxHdz18pQUNV",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Saving and Loading TensorFlow SavedModels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OGtK83g2vVki",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "To export our models to the TensorFlow **SavedModel** format, we use the `tf.keras.models.save_model(model, export_dir)` function—but with path to the directory, not to the filename! For example, to save a model called `my_model` in a folder called `saved_models` located in the current working directory we use:\n",
    "\n",
    "```python\n",
    "tf.keras.models.save_model(my_model, './saved_models')\n",
    "\n",
    "# Deprecated: Don't do this. It doesn't save the keras metadata, so the model will be loadable\n",
    "# only via TensorFlow, yet not via Keras!\n",
    "tf.saved_model.save(my_model, './saved_models')\n",
    "```\n",
    "\n",
    "It's important to note that here we have to provide the path to the directory where we want to save our model, **NOT** the name of the file. This is because SavedModels are not saved in a single file. Rather, when you save your model as a SavedModel, the `tf.saved_model.save()` function will create an `assets` folder, a `variables` folder, and a `saved_model.pb` file inside the directory you provided.\n",
    "\n",
    "The SavedModel files that are created contain:\n",
    "\n",
    "* A TensorFlow checkpoint containing the model weights.\n",
    "* A SavedModel proto containing the underlying TensorFlow graph. Separate graphs are saved for prediction (serving), training, and evaluation. If the model wasn't compiled before, then only the inference graph gets exported.\n",
    "* The model's architecture configuration if available.\n",
    "\n",
    "The SavedModel is a standalone serialization format for TensorFlow objects, supported by TensorFlow serving as well as TensorFlow implementations other than Python. It does not require the original model building code to run, which makes it useful for sharing or deploying in different platforms, such as mobile and embedded devices (with TensorFlow Lite), servers (with TensorFlow Serving), and even web browsers (with TensorFlow.js).\n",
    "\n",
    "In the cell below we save our trained model as a SavedModel. The name of the folder where we are going to save our model will correspond to the current time stamp. Again, this is useful if you are saving many models and want each of them to be saved in a unique directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 173
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "V2C0F3luxzlI",
    "outputId": "80a362e5-008f-4f54-ffb5-0b5577b5c46b",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "t = time.time()\n",
    "\n",
    "savedModel_directory = f'./Part_6/saved_models/{int(t)}'\n",
    "\n",
    "# Don't do this, or you can only load it with tf.saved_model.load() yet not with tf.keras.models.load_model()\n",
    "# tf.saved_model.save(model, savedModel_directory)\n",
    "\n",
    "# Instead, save the model in the protobuf format via keras. That way, you can load it with both tf.saved_model.load() and tg.keras.models.load_model()\n",
    "tf.keras.models.save_model(model, savedModel_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DBY1j0QEyjPi",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Once a model has been saved as a SavedModel, we can use `tf.saved_model.load(export_dir)` to re-load our model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rRx2y2M4AtKl",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "reloaded_SavedModel = tf.saved_model.load(savedModel_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wJwmzT1gAwew",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "It's important to note that the object returned by `tf.saved_model.load` is **NOT** a Keras object. Therefore, it doesn't have `.fit`, `.predict`, `.summary`, etc. methods. It is 100% independent of the code that created it. This means that in order to make predictions with our `reloaded_SavedModel` we need to use a different method than the one used with the re-loaded Keras model.\n",
    "\n",
    "To make predictions on a batch of images with a re-loaded SavedModel we have to use:\n",
    "\n",
    "```python\n",
    "reloaded_SavedModel(image_batch, training=False)\n",
    "```\n",
    "\n",
    "This will return a tensor with the predicted label probabilities for each image in the batch. Again, since we haven't done anything new to this re-loaded SavedModel, then both the `reloaded_SavedModel` and our original `model` should be identical copies. Therefore, they should make the same predictions on the same images. Let's check that this is true:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "ozMqD1ZoER5g",
    "outputId": "17769afa-1a1f-48c4-80e5-a389c80f4062",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 4ms/step\n",
      "2.3841858e-07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-18 13:38:05.605677: W tensorflow/core/kernels/data/cache_dataset_ops.cc:856] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2022-08-18 13:38:05.605900: W tensorflow/core/kernels/data/cache_dataset_ops.cc:856] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    }
   ],
   "source": [
    "for image_batch, label_batch in testing_batches.take(1):\n",
    "    prediction_1 = model.predict(image_batch)\n",
    "    prediction_2 = reloaded_SavedModel(image_batch, training=False).numpy()\n",
    "    difference = np.abs(prediction_1 - prediction_2)\n",
    "    print(difference.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3QZNNPkYFH3D",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We can also get back a full Keras model, from a TensorFlow SavedModel, by loading our SavedModel with the `tf.keras.models.load_model` function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 425
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "0BxFJcGLyMTD",
    "outputId": "a2fefa76-57b5-4a9e-8c05-b8a1ae7f31a2",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten (Flatten)           (None, 784)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               401920    \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 512)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 256)               131328    \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 128)               32896     \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 567,434\n",
      "Trainable params: 567,434\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "reloaded_keras_model_from_SavedModel = tf.keras.models.load_model(savedModel_directory)\n",
    "\n",
    "reloaded_keras_model_from_SavedModel.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FomAlrxnQnm8",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Saving Models During Training\n",
    "\n",
    "We have seen that when we train a model with a validation set, the value of the validation loss changes through the training process. Since the value of the validation loss is an indicator of how well our model will generalize to new data, it will be great if could save our model at each step of the training process and then only keep the version with the lowest validation loss. \n",
    "\n",
    "We can do this in `tf.keras` by using the following callback:\n",
    "\n",
    "```python\n",
    "tf.keras.callbacks.ModelCheckpoint('./best_model.h5', monitor='val_loss', save_best_only=True)\n",
    "```\n",
    "This callback will save the model as a Keras HDF5 file after every epoch. With the `save_best_only=True` argument, this callback will first check the validation loss of the latest model against the one previously saved. The callback will only save the latest model and overwrite the old one, if the latest model has a lower validation loss than the one previously saved. This will guarantee that will end up with the version of the model that achieved the lowest validation loss during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 765
    },
    "colab_type": "code",
    "id": "vvsuAeUQ1WKR",
    "outputId": "b8ee7834-f46e-4141-d61c-83cd7d72a333",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "750/750 [==============================] - 3s 3ms/step - loss: 0.5241 - accuracy: 0.8154 - val_loss: 0.4128 - val_accuracy: 0.8468\n",
      "Epoch 2/100\n",
      "750/750 [==============================] - 2s 3ms/step - loss: 0.3793 - accuracy: 0.8606 - val_loss: 0.3583 - val_accuracy: 0.8641\n",
      "Epoch 3/100\n",
      "750/750 [==============================] - 2s 3ms/step - loss: 0.3422 - accuracy: 0.8735 - val_loss: 0.3375 - val_accuracy: 0.8742\n",
      "Epoch 4/100\n",
      "750/750 [==============================] - 2s 3ms/step - loss: 0.3136 - accuracy: 0.8834 - val_loss: 0.3438 - val_accuracy: 0.8758\n",
      "Epoch 5/100\n",
      "750/750 [==============================] - 2s 3ms/step - loss: 0.2992 - accuracy: 0.8875 - val_loss: 0.3483 - val_accuracy: 0.8698\n",
      "Epoch 6/100\n",
      "750/750 [==============================] - 2s 3ms/step - loss: 0.2831 - accuracy: 0.8950 - val_loss: 0.2975 - val_accuracy: 0.8907\n",
      "Epoch 7/100\n",
      "750/750 [==============================] - 2s 3ms/step - loss: 0.2680 - accuracy: 0.9000 - val_loss: 0.3100 - val_accuracy: 0.8888\n",
      "Epoch 8/100\n",
      "750/750 [==============================] - 2s 3ms/step - loss: 0.2574 - accuracy: 0.9028 - val_loss: 0.3048 - val_accuracy: 0.8932\n",
      "Epoch 9/100\n",
      "750/750 [==============================] - 2s 3ms/step - loss: 0.2437 - accuracy: 0.9076 - val_loss: 0.2920 - val_accuracy: 0.8932\n",
      "Epoch 10/100\n",
      "750/750 [==============================] - 2s 3ms/step - loss: 0.2374 - accuracy: 0.9100 - val_loss: 0.2993 - val_accuracy: 0.8934\n",
      "Epoch 11/100\n",
      "750/750 [==============================] - 2s 3ms/step - loss: 0.2262 - accuracy: 0.9154 - val_loss: 0.3379 - val_accuracy: 0.8865\n",
      "Epoch 12/100\n",
      "750/750 [==============================] - 2s 3ms/step - loss: 0.2213 - accuracy: 0.9164 - val_loss: 0.2987 - val_accuracy: 0.8903\n",
      "Epoch 13/100\n",
      "750/750 [==============================] - 2s 3ms/step - loss: 0.2087 - accuracy: 0.9202 - val_loss: 0.3155 - val_accuracy: 0.8892\n",
      "Epoch 14/100\n",
      "750/750 [==============================] - 2s 3ms/step - loss: 0.2040 - accuracy: 0.9228 - val_loss: 0.2849 - val_accuracy: 0.8959\n",
      "Epoch 15/100\n",
      "750/750 [==============================] - 2s 3ms/step - loss: 0.1961 - accuracy: 0.9249 - val_loss: 0.3112 - val_accuracy: 0.8996\n",
      "Epoch 16/100\n",
      "750/750 [==============================] - 2s 3ms/step - loss: 0.1901 - accuracy: 0.9276 - val_loss: 0.2863 - val_accuracy: 0.9001\n",
      "Epoch 17/100\n",
      "750/750 [==============================] - 2s 3ms/step - loss: 0.1792 - accuracy: 0.9310 - val_loss: 0.3157 - val_accuracy: 0.8993\n",
      "Epoch 18/100\n",
      "750/750 [==============================] - 2s 3ms/step - loss: 0.1781 - accuracy: 0.9316 - val_loss: 0.3451 - val_accuracy: 0.8935\n",
      "Epoch 19/100\n",
      "750/750 [==============================] - 2s 3ms/step - loss: 0.1733 - accuracy: 0.9346 - val_loss: 0.3073 - val_accuracy: 0.8982\n",
      "Epoch 20/100\n",
      "750/750 [==============================] - 2s 3ms/step - loss: 0.1673 - accuracy: 0.9361 - val_loss: 0.3352 - val_accuracy: 0.8951\n",
      "Epoch 21/100\n",
      "750/750 [==============================] - 2s 3ms/step - loss: 0.1619 - accuracy: 0.9385 - val_loss: 0.3293 - val_accuracy: 0.8976\n",
      "Epoch 22/100\n",
      "750/750 [==============================] - 2s 3ms/step - loss: 0.1524 - accuracy: 0.9419 - val_loss: 0.3566 - val_accuracy: 0.8893\n",
      "Epoch 23/100\n",
      "750/750 [==============================] - 2s 3ms/step - loss: 0.1527 - accuracy: 0.9411 - val_loss: 0.3383 - val_accuracy: 0.8925\n",
      "Epoch 24/100\n",
      "750/750 [==============================] - 2s 3ms/step - loss: 0.1444 - accuracy: 0.9441 - val_loss: 0.3339 - val_accuracy: 0.8963\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=(28, 28, 1)),\n",
    "    tf.keras.layers.Dense(256, activation='relu'),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Stop training when there is no improvement in the validation loss for 10 consecutive epochs\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10)\n",
    "\n",
    "# Save the Model with the lowest validation loss\n",
    "save_best = tf.keras.callbacks.ModelCheckpoint('./Part_6/hdf5/best_model.h5',\n",
    "                                               monitor='val_loss',\n",
    "                                               save_best_only=True)\n",
    "\n",
    "history = model.fit(training_batches,\n",
    "                    epochs=100,\n",
    "                    validation_data=validation_batches,\n",
    "                    callbacks=[early_stopping, save_best])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sz4snGQsR2Mg",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "188/188 [==============================] - 0s 2ms/step - loss: 0.2849 - accuracy: 0.8959\n",
      "Validation\tloss = 0.285, accuracy = 0.896\n",
      "\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.3372 - accuracy: 0.8887\n",
      "Test\t\tloss = 0.337, accuracy = 0.889\n"
     ]
    }
   ],
   "source": [
    "reloaded_best_model = tf.keras.models.load_model('./Part_6/hdf5/best_model.h5')\n",
    "\n",
    "loss, accuracy = reloaded_best_model.evaluate(validation_batches)\n",
    "print(f'Validation\\t{loss = :.3f}, {accuracy = :.3f}\\n')\n",
    "\n",
    "loss, accuracy = reloaded_best_model.evaluate(testing_batches)\n",
    "print(f'Test\\t\\t{loss = :.3f}, {accuracy = :.3f}')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Part 6 - Saving and Loading Models.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "name": "tf",
   "language": "python",
   "display_name": "Python (TF)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}